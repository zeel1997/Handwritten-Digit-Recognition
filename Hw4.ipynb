{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split,KFold,RepeatedKFold\n",
    "from sklearn.metrics import accuracy_score,log_loss\n",
    "from sklearn.neural_network import multilayer_perceptron\n",
    "from sklearn.model_selection import GridSearchCV,PredefinedSplit\n",
    "from sklearn.feature_selection import SelectKBest,chi2,SelectFromModel\n",
    "from sklearn.svm import SVC\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(2)\n",
    "pd.set_option('display.max_colwidth',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df=pd.read_csv(\"data/optdigits.tra\",header=None)\n",
    "training_df=training_df[((training_df.iloc[:,-1]==1) | (training_df.iloc[:,-1]==7))]\n",
    "training_df.replace({7:0},inplace=True)\n",
    "DIMENSIONS=64\n",
    "models=[]\n",
    "data_partitions=[]\n",
    "kfold=KFold(n_splits=10,shuffle=True,random_state=2)\n",
    "for train_index,test_index in kfold.split(training_df):\n",
    "    data_partitions.append((training_df.iloc[train_index,:-1].values,training_df.iloc[train_index,-1].values,training_df.iloc[test_index,:-1].values,training_df.iloc[test_index,-1].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self,learning_rate,momentum,dimensions,a,b):\n",
    "        self.learning_rate=learning_rate\n",
    "        self.momentum=momentum\n",
    "        self.dimensions=dimensions\n",
    "        self.weights=np.random.uniform(low=0,high=0.0001,size=(dimensions,1))\n",
    "        self.a=a\n",
    "        self.b=b\n",
    "    def print_model_parameters(self,i):\n",
    "        print(\"*\"*45)\n",
    "        print(\"Run:{0}\\nInitial learning rate:{1}\\nInitial momentum:{2}\".format(i,self.learning_rate,self.momentum))\n",
    "    def sigmoid_activation(self,x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    def cross_entropy(self,y_true,y_pred):\n",
    "        return log_loss(y_true,y_pred)\n",
    "    def train(self,x_train,y_train,n_iter=50):\n",
    "        #print(x_train.shape)\n",
    "        errors=[]\n",
    "        converged=False\n",
    "        while converged==False and n_iter!=0:\n",
    "            error=0\n",
    "            n_iter-=1\n",
    "            predictions=[]\n",
    "            temp=np.zeros(shape=(self.dimensions))\n",
    "            d_weights=np.zeros(shape=(self.dimensions))\n",
    "            for i in range(x_train.shape[0]):\n",
    "                o=0\n",
    "                for j in range(x_train.shape[1]):\n",
    "                    o+=(self.weights[j]*x_train[i,j])\n",
    "                y_pred=self.sigmoid_activation(o)\n",
    "                for j in range(x_train.shape[1]):\n",
    "                    #d_weights[j]+=learning_rate*(y_train[i]-y_pred)*x_train[i,j]\n",
    "                    d_weights[j]=(self.learning_rate*(y_train[i]-y_pred)*x_train[i,j])+(self.momentum*d_weights[j])\n",
    "                predictions.append(y_train[i]-y_pred)\n",
    "            isDecreasing=True\n",
    "            errors.append(self.cross_entropy(y_train,np.array(predictions)))\n",
    "            current_error=errors[-1]\n",
    "            for i in range(len(errors)-1):\n",
    "                if errors[i]<=current_error:\n",
    "                    isDecreasing=False\n",
    "                    break\n",
    "            if isDecreasing:\n",
    "                self.learning_rate+=self.a\n",
    "            else:\n",
    "                self.learning_rate-=(self.b*self.learning_rate)\n",
    "            for j in range(self.dimensions):\n",
    "                #self.weights[j]+=self.learning_rate*d_weights[j]\n",
    "                self.weights[j]+=(d_weights[j])\n",
    "            try:\n",
    "                if errors[-2]==errors[-1]:\n",
    "                    converged=True\n",
    "            except IndexError:\n",
    "                continue\n",
    "        self.evaluate(\"Training\",y_train,self.predict(x_train))\n",
    "    def predict(self,x):\n",
    "        y_pred=self.sigmoid_activation(np.sum(x*self.weights.T,axis=1))\n",
    "        y_pred=np.array(y_pred>0.5,dtype=np.int16)\n",
    "        return y_pred\n",
    "    def evaluate(self,string,y_true,y_pred):\n",
    "        print(\"{0} error rate for run :{1}\".format(string,1-accuracy_score(y_true,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************\n",
      "Run:0\n",
      "Initial learning rate:0.0004249480807741736\n",
      "Initial momentum:0.9868188372777147\n",
      "Training error rate for run :0.008595988538681931\n",
      "Test error rate for run :0.0\n",
      "*********************************************\n",
      "Run:1\n",
      "Initial learning rate:0.0002873857846716795\n",
      "Initial momentum:0.9888680194471693\n",
      "Training error rate for run :0.01002865329512892\n",
      "Test error rate for run :0.0\n",
      "*********************************************\n",
      "Run:2\n",
      "Initial learning rate:0.00011435976947699817\n",
      "Initial momentum:0.9784045945797017\n",
      "Training error rate for run :0.007163323782234943\n",
      "Test error rate for run :0.0\n",
      "*********************************************\n",
      "Run:3\n",
      "Initial learning rate:0.00021740385762580194\n",
      "Initial momentum:0.9393618679876573\n",
      "Training error rate for run :0.011461318051575908\n",
      "Test error rate for run :0.012820512820512775\n",
      "*********************************************\n",
      "Run:4\n",
      "Initial learning rate:0.000348091504172011\n",
      "Initial momentum:0.9591138016454379\n",
      "Training error rate for run :0.008595988538681931\n",
      "Test error rate for run :0.012820512820512775\n",
      "*********************************************\n",
      "Run:5\n",
      "Initial learning rate:0.0009757783365261536\n",
      "Initial momentum:0.9527554235515348\n",
      "Training error rate for run :0.011461318051575908\n",
      "Test error rate for run :0.038461538461538436\n",
      "*********************************************\n",
      "Run:6\n",
      "Initial learning rate:0.0005662066538326092\n",
      "Initial momentum:0.9096548425081732\n",
      "Training error rate for run :0.01573676680972813\n",
      "Test error rate for run :0.025974025974025983\n",
      "*********************************************\n",
      "Run:7\n",
      "Initial learning rate:0.0009669377200554579\n",
      "Initial momentum:0.9776414611607172\n",
      "Training error rate for run :0.005722460658083017\n",
      "Test error rate for run :0.012987012987012991\n",
      "*********************************************\n",
      "Run:8\n",
      "Initial learning rate:0.0002858724105078628\n",
      "Initial momentum:0.9833693337862925\n",
      "Training error rate for run :0.007153075822603716\n",
      "Test error rate for run :0.0\n",
      "*********************************************\n",
      "Run:9\n",
      "Initial learning rate:0.00029583745295984863\n",
      "Initial momentum:0.9792504418916992\n",
      "Training error rate for run :0.01716738197424894\n",
      "Test error rate for run :0.012987012987012991\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    learning_rate=np.random.uniform(low=0.0001,high=0.001)\n",
    "    momentum=np.random.uniform(low=0.9,high=0.99)\n",
    "    model=LogisticRegression(learning_rate,momentum,DIMENSIONS,0.0001,0.0002)\n",
    "    x_train,y_train,x_test,y_test=data_partitions[i]\n",
    "    model.print_model_parameters(i)\n",
    "    model.train(x_train,y_train,10)\n",
    "    models.append(model)\n",
    "    model.evaluate(\"Test\",y_test,model.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_avg_weights=[]\n",
    "for model in models:\n",
    "    abs_avg_weights.append(np.abs(model.weights))\n",
    "abs_avg_weights=np.array(abs_avg_weights)\n",
    "abs_avg_weights=abs_avg_weights.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "after_elimination_10=abs_avg_weights.argsort(axis=0)[:int(0.9*DIMENSIONS)]\n",
    "after_elimination_25=abs_avg_weights.argsort(axis=0)[:int(0.75*DIMENSIONS)]\n",
    "after_elimination_50=abs_avg_weights.argsort(axis=0)[:int(0.5*DIMENSIONS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************\n",
      "Run:0\n",
      "Initial learning rate:0.00037560963112285586\n",
      "Initial momentum:0.9232292498149266\n",
      "Training error rate for run :0.504297994269341\n",
      "Test error rate for run :0.47435897435897434\n",
      "*********************************************\n",
      "Run:1\n",
      "Initial learning rate:0.00016473354972979372\n",
      "Initial momentum:0.9815996514641392\n",
      "Training error rate for run :0.501432664756447\n",
      "Test error rate for run :0.5\n",
      "*********************************************\n",
      "Run:2\n",
      "Initial learning rate:0.0005741687889834052\n",
      "Initial momentum:0.9211236279668327\n",
      "Training error rate for run :0.49426934097421205\n",
      "Test error rate for run :0.5641025641025641\n",
      "*********************************************\n",
      "Run:3\n",
      "Initial learning rate:0.0009151681215947962\n",
      "Initial momentum:0.9551991310330916\n",
      "Training error rate for run :0.497134670487106\n",
      "Test error rate for run :0.5384615384615384\n",
      "*********************************************\n",
      "Run:4\n",
      "Initial learning rate:0.0008783852416275361\n",
      "Initial momentum:0.9786846305950816\n",
      "Training error rate for run :0.5128939828080229\n",
      "Test error rate for run :0.39743589743589747\n",
      "*********************************************\n",
      "Run:5\n",
      "Initial learning rate:0.00025952953023812157\n",
      "Initial momentum:0.9650569759597353\n",
      "Training error rate for run :0.49283667621776506\n",
      "Test error rate for run :0.5769230769230769\n",
      "*********************************************\n",
      "Run:6\n",
      "Initial learning rate:0.0007626531506790111\n",
      "Initial momentum:0.9690087399005315\n",
      "Training error rate for run :0.5107296137339056\n",
      "Test error rate for run :0.4155844155844156\n",
      "*********************************************\n",
      "Run:7\n",
      "Initial learning rate:0.00017446680619471523\n",
      "Initial momentum:0.9125816826499482\n",
      "Training error rate for run :0.49499284692417744\n",
      "Test error rate for run :0.5584415584415585\n",
      "*********************************************\n",
      "Run:8\n",
      "Initial learning rate:0.0007630184510359064\n",
      "Initial momentum:0.9202744231483934\n",
      "Training error rate for run :0.5035765379113019\n",
      "Test error rate for run :0.48051948051948057\n",
      "*********************************************\n",
      "Run:9\n",
      "Initial learning rate:0.0005948244506905345\n",
      "Initial momentum:0.9114324005948881\n",
      "Training error rate for run :0.5007153075822603\n",
      "Test error rate for run :0.5064935064935066\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    learning_rate=np.random.uniform(low=0.0001,high=0.001)\n",
    "    momentum=np.random.uniform(low=0.9,high=0.99)\n",
    "    model=LogisticRegression(learning_rate,momentum,after_elimination_10.shape[0],0.0001,0.0002)\n",
    "    x_train,y_train,x_test,y_test=data_partitions[i]\n",
    "    model.print_model_parameters(i)\n",
    "    model.train(x_train[:,after_elimination_10].reshape(x_train.shape[0],after_elimination_10.shape[0]),y_train,10)\n",
    "    model.evaluate(\"Test\",y_test,model.predict(x_test[:,after_elimination_10].reshape(x_test.shape[0],after_elimination_10.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************\n",
      "Run:0\n",
      "Initial learning rate:0.0007774359691369259\n",
      "Initial momentum:0.9544633798414398\n",
      "Training error rate for run :0.504297994269341\n",
      "Test error rate for run :0.47435897435897434\n",
      "*********************************************\n",
      "Run:1\n",
      "Initial learning rate:0.0004777793791981728\n",
      "Initial momentum:0.9480409078649433\n",
      "Training error rate for run :0.501432664756447\n",
      "Test error rate for run :0.5\n",
      "*********************************************\n",
      "Run:2\n",
      "Initial learning rate:0.00026045080774150776\n",
      "Initial momentum:0.9805967946128417\n",
      "Training error rate for run :0.49426934097421205\n",
      "Test error rate for run :0.5641025641025641\n",
      "*********************************************\n",
      "Run:3\n",
      "Initial learning rate:0.00011042210500974593\n",
      "Initial momentum:0.907610251531215\n",
      "Training error rate for run :0.497134670487106\n",
      "Test error rate for run :0.5384615384615384\n",
      "*********************************************\n",
      "Run:4\n",
      "Initial learning rate:0.0009810810546223606\n",
      "Initial momentum:0.9247716554742655\n",
      "Training error rate for run :0.5128939828080229\n",
      "Test error rate for run :0.39743589743589747\n",
      "*********************************************\n",
      "Run:5\n",
      "Initial learning rate:0.0005681712230265277\n",
      "Initial momentum:0.9265909854932945\n",
      "Training error rate for run :0.49283667621776506\n",
      "Test error rate for run :0.5769230769230769\n",
      "*********************************************\n",
      "Run:6\n",
      "Initial learning rate:0.0008339874752214131\n",
      "Initial momentum:0.9253356454268665\n",
      "Training error rate for run :0.5107296137339056\n",
      "Test error rate for run :0.4155844155844156\n",
      "*********************************************\n",
      "Run:7\n",
      "Initial learning rate:0.0009360449221826795\n",
      "Initial momentum:0.925168623970013\n",
      "Training error rate for run :0.49499284692417744\n",
      "Test error rate for run :0.5584415584415585\n",
      "*********************************************\n",
      "Run:8\n",
      "Initial learning rate:0.0002673807756175192\n",
      "Initial momentum:0.915359390227272\n",
      "Training error rate for run :0.5035765379113019\n",
      "Test error rate for run :0.48051948051948057\n",
      "*********************************************\n",
      "Run:9\n",
      "Initial learning rate:0.0008203105761141246\n",
      "Initial momentum:0.9856704368364275\n",
      "Training error rate for run :0.5007153075822603\n",
      "Test error rate for run :0.5064935064935066\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    learning_rate=np.random.uniform(low=0.0001,high=0.001)\n",
    "    momentum=np.random.uniform(low=0.9,high=0.99)\n",
    "    model=LogisticRegression(learning_rate,momentum,after_elimination_25.shape[0],0.0001,0.0002)\n",
    "    x_train,y_train,x_test,y_test=data_partitions[i]\n",
    "    model.print_model_parameters(i)\n",
    "    model.train(x_train[:,after_elimination_25].reshape(x_train.shape[0],after_elimination_25.shape[0]),y_train,10)\n",
    "    model.evaluate(\"Test\",y_test,model.predict(x_test[:,after_elimination_25].reshape(x_test.shape[0],after_elimination_25.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************\n",
      "Run:0\n",
      "Initial learning rate:0.0004947817419852202\n",
      "Initial momentum:0.9874806501390709\n",
      "Training error rate for run :0.504297994269341\n",
      "Test error rate for run :0.47435897435897434\n",
      "*********************************************\n",
      "Run:1\n",
      "Initial learning rate:0.00023758244632954935\n",
      "Initial momentum:0.925130120617303\n",
      "Training error rate for run :0.501432664756447\n",
      "Test error rate for run :0.5\n",
      "*********************************************\n",
      "Run:2\n",
      "Initial learning rate:0.00012469559605250816\n",
      "Initial momentum:0.9097590767721605\n",
      "Training error rate for run :0.49426934097421205\n",
      "Test error rate for run :0.5641025641025641\n",
      "*********************************************\n",
      "Run:3\n",
      "Initial learning rate:0.0008187296016928157\n",
      "Initial momentum:0.9880406463875171\n",
      "Training error rate for run :0.497134670487106\n",
      "Test error rate for run :0.5384615384615384\n",
      "*********************************************\n",
      "Run:4\n",
      "Initial learning rate:0.00030792969588006383\n",
      "Initial momentum:0.9189242306437161\n",
      "Training error rate for run :0.5128939828080229\n",
      "Test error rate for run :0.39743589743589747\n",
      "*********************************************\n",
      "Run:5\n",
      "Initial learning rate:0.0002942464308762278\n",
      "Initial momentum:0.9890959361171483\n",
      "Training error rate for run :0.49283667621776506\n",
      "Test error rate for run :0.5769230769230769\n",
      "*********************************************\n",
      "Run:6\n",
      "Initial learning rate:0.0007366376269144619\n",
      "Initial momentum:0.9847989498206356\n",
      "Training error rate for run :0.5107296137339056\n",
      "Test error rate for run :0.4155844155844156\n",
      "*********************************************\n",
      "Run:7\n",
      "Initial learning rate:0.0005526311541524156\n",
      "Initial momentum:0.9602443489924879\n",
      "Training error rate for run :0.49499284692417744\n",
      "Test error rate for run :0.5584415584415585\n",
      "*********************************************\n",
      "Run:8\n",
      "Initial learning rate:0.00021968019479733965\n",
      "Initial momentum:0.9301280539960259\n",
      "Training error rate for run :0.5035765379113019\n",
      "Test error rate for run :0.48051948051948057\n",
      "*********************************************\n",
      "Run:9\n",
      "Initial learning rate:0.0002945857485972865\n",
      "Initial momentum:0.9223067015778289\n",
      "Training error rate for run :0.5007153075822603\n",
      "Test error rate for run :0.5064935064935066\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    learning_rate=np.random.uniform(low=0.0001,high=0.001)\n",
    "    momentum=np.random.uniform(low=0.9,high=0.99)\n",
    "    model=LogisticRegression(learning_rate,momentum,after_elimination_50.shape[0],0.0001,0.0002)\n",
    "    x_train,y_train,x_test,y_test=data_partitions[i]\n",
    "    model.print_model_parameters(i)\n",
    "    model.train(x_train[:,after_elimination_50].reshape(x_train.shape[0],after_elimination_50.shape[0]),y_train,10)\n",
    "    model.evaluate(\"Test\",y_test,model.predict(x_test[:,after_elimination_50].reshape(x_test.shape[0],after_elimination_50.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 0\n",
      "Fitting 2 folds for each of 32 candidates, totalling 64 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  64 out of  64 | elapsed:    3.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 1\n",
      "Fitting 2 folds for each of 32 candidates, totalling 64 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  64 out of  64 | elapsed:    3.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 2\n",
      "Fitting 2 folds for each of 32 candidates, totalling 64 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  64 out of  64 | elapsed:    3.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 3\n",
      "Fitting 2 folds for each of 32 candidates, totalling 64 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  64 out of  64 | elapsed:    3.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 4\n",
      "Fitting 2 folds for each of 32 candidates, totalling 64 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  64 out of  64 | elapsed:    3.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 5\n",
      "Fitting 2 folds for each of 32 candidates, totalling 64 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  64 out of  64 | elapsed:    2.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 6\n",
      "Fitting 2 folds for each of 32 candidates, totalling 64 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  64 out of  64 | elapsed:    3.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 7\n",
      "Fitting 2 folds for each of 32 candidates, totalling 64 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  64 | elapsed:    2.9s remaining:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  64 out of  64 | elapsed:    3.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 8\n",
      "Fitting 2 folds for each of 32 candidates, totalling 64 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  64 out of  64 | elapsed:    3.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 9\n",
      "Fitting 2 folds for each of 32 candidates, totalling 64 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  64 | elapsed:    2.6s remaining:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  64 out of  64 | elapsed:    3.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Test scores                                         Parameters  \\\n",
      "0     0.012821  {'alpha': 0.0001, 'hidden_layer_sizes': (30, 1...   \n",
      "1     0.012821  {'alpha': 1e-05, 'hidden_layer_sizes': (100, 1...   \n",
      "2     0.012821  {'alpha': 0.001, 'hidden_layer_sizes': (100, 1...   \n",
      "3     0.000000  {'alpha': 0.0001, 'hidden_layer_sizes': (30, 1...   \n",
      "4     0.012821  {'alpha': 0.1, 'hidden_layer_sizes': (30, 10, ...   \n",
      "5     0.576923  {'alpha': 1e-05, 'hidden_layer_sizes': (30, 10...   \n",
      "6     0.415584  {'alpha': 1e-05, 'hidden_layer_sizes': (100, 1...   \n",
      "7     0.441558  {'alpha': 0.0001, 'hidden_layer_sizes': (30, 1...   \n",
      "8     0.012987  {'alpha': 0.0001, 'hidden_layer_sizes': (100, ...   \n",
      "9     0.493506  {'alpha': 1e-05, 'hidden_layer_sizes': (30, 10...   \n",
      "\n",
      "   Test error with K Best feature selection  Test error with Tree selection  \n",
      "0                                  0.000000                        0.500000  \n",
      "1                                  0.012821                        0.000000  \n",
      "2                                  0.000000                        0.000000  \n",
      "3                                  0.461538                        0.000000  \n",
      "4                                  0.012821                        0.000000  \n",
      "5                                  0.012821                        0.576923  \n",
      "6                                  0.012987                        0.025974  \n",
      "7                                  0.000000                        0.012987  \n",
      "8                                  0.480519                        0.025974  \n",
      "9                                  0.493506                        0.000000  \n"
     ]
    }
   ],
   "source": [
    "parameters={\n",
    "    'hidden_layer_sizes':[(10,20),(50,30),(100,10,2),(30,10,2)],\n",
    "    'solver':['adam','sgd'],\n",
    "    'alpha':[0.0001,0.00001,0.001,0.1]\n",
    "}\n",
    "skmodels=[]\n",
    "worst_params=[]\n",
    "scores=[]\n",
    "kbest=[]\n",
    "tree_selection=[]\n",
    "for i,(x_train,y_train,x_test,y_test) in enumerate(data_partitions):\n",
    "    print(\"\\nRun {0}\".format(i))\n",
    "    model=GridSearchCV(MLPClassifier(),param_grid=parameters,n_jobs=-1,cv=RepeatedKFold(n_splits=2,n_repeats=1,random_state=2),verbose=3,scoring='neg_log_loss')\n",
    "    model.fit(x_train,y_train)\n",
    "    worst_training_error=model.cv_results_['mean_test_score']\n",
    "    worst_params.append(model.cv_results_['params'][np.argmin(worst_training_error)])\n",
    "    test_model=MLPClassifier(**worst_params[-1])\n",
    "    test_model.fit(x_train,y_train)\n",
    "    \n",
    "    scores.append(1-accuracy_score(y_test,test_model.predict(x_test)))\n",
    "    selector=SelectKBest(chi2,k=45)\n",
    "    x_train_=selector.fit_transform(x_train,y_train)\n",
    "    x_test_=selector.transform(x_test)\n",
    "    test_model.fit(x_train_,y_train)\n",
    "    kbest.append(1-accuracy_score(y_test,test_model.predict(x_test_)))\n",
    "    \n",
    "    selector=SelectFromModel(SVC(kernel='linear'))\n",
    "    x_train_=selector.fit_transform(x_train,y_train)\n",
    "    x_test_=selector.transform(x_test)\n",
    "    test_model.fit(x_train_,y_train)\n",
    "    tree_selection.append(1-accuracy_score(y_test,test_model.predict(x_test_)))\n",
    "    \n",
    "    skmodels.append(model)\n",
    "scores=np.array(scores)\n",
    "worst_params=np.array(worst_params)\n",
    "df=pd.DataFrame({\"Test scores\":scores,\"Parameters\":worst_params,\"Test error with \\nK Best feature selection\":kbest,\"Test error with \\nTree based selection\":tree_selection})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
