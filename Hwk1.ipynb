{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### https://www.kaggle.com/uciml/pima-indians-diabetes-database - Download the indian diabetes dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Import relevant commands for numpy, pandas, sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "FOLDS=10\n",
    "ALPHA=0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Using the appropriate pandas function, read the diabetes.csv into a dataframe. Pay good attention to the necessary arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('diabetes.csv', sep=\",\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
       "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
       "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
       "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
       "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
       "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
       "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
       "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  768.000000                768.000000  768.000000  768.000000  \n",
       "mean    31.992578                  0.471876   33.240885    0.348958  \n",
       "std      7.884160                  0.331329   11.760232    0.476951  \n",
       "min      0.000000                  0.078000   21.000000    0.000000  \n",
       "25%     27.300000                  0.243750   24.000000    0.000000  \n",
       "50%     32.000000                  0.372500   29.000000    0.000000  \n",
       "75%     36.600000                  0.626250   41.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.use naivebayes, logistic regression and 3-nn classifiers (library) to train on the training sets and compute training and validation errors for each fold. The target label is Outcome.\n",
    "\n",
    "1. Split the dataset into training and testing set and apply all operations on training set.\n",
    "1. Create 10 folds on training set.\n",
    "2. At each fold, train all classifiers and calculate their training and validation error at each fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Errors:\n",
      "             3-NN  Logistic Regression  Naive Bayes\n",
      "Fold 1   0.153986             0.215580     0.235507\n",
      "Fold 2   0.159420             0.217391     0.240942\n",
      "Fold 3   0.163043             0.217391     0.244565\n",
      "Fold 4   0.164855             0.233696     0.240942\n",
      "Fold 5   0.168174             0.218807     0.238698\n",
      "Fold 6   0.164557             0.224231     0.244123\n",
      "Fold 7   0.146474             0.213382     0.236890\n",
      "Fold 8   0.162749             0.216998     0.244123\n",
      "Fold 9   0.166365             0.224231     0.238698\n",
      "Fold 10  0.164557             0.220615     0.247740\n",
      "\n",
      "\n",
      "Validation Errors:\n",
      "             3-NN  Logistic Regression  Naive Bayes\n",
      "Fold 1   0.153986             0.258065     0.274194\n",
      "Fold 2   0.159420             0.193548     0.290323\n",
      "Fold 3   0.163043             0.193548     0.225806\n",
      "Fold 4   0.164855             0.209677     0.225806\n",
      "Fold 5   0.168174             0.245902     0.311475\n",
      "Fold 6   0.164557             0.196721     0.180328\n",
      "Fold 7   0.146474             0.295082     0.311475\n",
      "Fold 8   0.162749             0.245902     0.245902\n",
      "Fold 9   0.166365             0.295082     0.229508\n",
      "Fold 10  0.164557             0.213115     0.196721\n"
     ]
    }
   ],
   "source": [
    "features=data.iloc[:,:-1].values\n",
    "labels=data.iloc[:,-1].values\n",
    "x_train,x_test,y_train,y_test=train_test_split(features,labels,train_size=0.8)\n",
    "\n",
    "knn_classifier=KNeighborsClassifier(n_neighbors=3)\n",
    "nb_classifier=GaussianNB()\n",
    "log_reg_classifier=LogisticRegression(solver='liblinear')\n",
    "\n",
    "kfold=KFold(n_splits=FOLDS,shuffle=True)\n",
    "\n",
    "knn_validation_errors=[]\n",
    "nb_validation_errors=[]\n",
    "log_reg_validation_errors=[]\n",
    "\n",
    "knn_training_errors=[]\n",
    "nb_training_errors=[]\n",
    "log_reg_training_errors=[]\n",
    "\n",
    "for train_indices,validation_indices in kfold.split(y_train):\n",
    "    nb_classifier.fit(x_train[train_indices],y_train[train_indices])\n",
    "    training_predictions=nb_classifier.predict(x_train[train_indices])\n",
    "    nb_training_errors.append(np.sum(training_predictions!=y_train[train_indices])/len(training_predictions))\n",
    "    predictions=nb_classifier.predict(x_train[validation_indices])\n",
    "    nb_validation_errors.append(np.sum(predictions!=y_train[validation_indices])/len(predictions))\n",
    "    \n",
    "    knn_classifier.fit(x_train[train_indices],y_train[train_indices])\n",
    "    training_predictions=knn_classifier.predict(x_train[train_indices])\n",
    "    knn_training_errors.append(np.sum(training_predictions!=y_train[train_indices])/len(training_predictions))\n",
    "    predictions=knn_classifier.predict(x_train[validation_indices])\n",
    "    knn_validation_errors.append(np.sum(predictions!=y_train[validation_indices])/len(predictions))\n",
    "    \n",
    "    log_reg_classifier.fit(x_train[train_indices],y_train[train_indices])\n",
    "    training_predictions=log_reg_classifier.predict(x_train[train_indices])\n",
    "    log_reg_training_errors.append(np.sum(training_predictions!=y_train[train_indices])/len(training_predictions))\n",
    "    predictions=log_reg_classifier.predict(x_train[validation_indices])\n",
    "    log_reg_validation_errors.append(np.sum(predictions!=y_train[validation_indices])/len(predictions))\n",
    "\n",
    "    \n",
    "knn_validation_errors=np.array(knn_validation_errors)\n",
    "nb_validation_errors=np.array(nb_validation_errors)\n",
    "log_reg_validation_errors=np.array(log_reg_validation_errors)\n",
    "\n",
    "training_errors=pd.DataFrame({\"3-NN\":knn_training_errors,\"Logistic Regression\":log_reg_training_errors,\"Naive Bayes\":nb_training_errors},index=[\"Fold \"+str(i+1) for i in range(FOLDS)])\n",
    "validation_errors=pd.DataFrame({\"3-NN\":knn_training_errors,\"Logistic Regression\":log_reg_validation_errors,\"Naive Bayes\":nb_validation_errors},index=[\"Fold \"+str(i+1) for i in range(FOLDS)])\n",
    "\n",
    "print(\"Training Errors:\")\n",
    "print(training_errors)\n",
    "print(\"\\n\\nValidation Errors:\")\n",
    "print(validation_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.is the error of naive bayes <0.2 with confidence 0.9\n",
    "\n",
    "1. We need to perform **t-test** to check if the error is less than 0.2\n",
    "2. Confidence level=0.9\n",
    "3. p0=0.2\n",
    "4. Calculate t-value and compare it with t-critical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T value: 3.323858116430678\n",
      "T critical: 1.3830287383964925\n",
      "No\n"
     ]
    }
   ],
   "source": [
    "mean=np.mean(nb_validation_errors)\n",
    "std_dev=np.std(nb_validation_errors)\n",
    "t_k_1=np.sqrt(FOLDS)*(mean-0.2)/std_dev\n",
    "df=FOLDS-1\n",
    "t=stats.t.ppf(ALPHA,df)\n",
    "\n",
    "print(\"T value:\",t_k_1)\n",
    "print(\"T critical:\",t)\n",
    "if t_k_1>t:\n",
    "    print(\"No\")\n",
    "else:\n",
    "    print(\"Yes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.have  naive bayes and knn the same error?\n",
    "1. We need to perform **K-Fold Cross Validation Paired Test** to check whether 2 classifiers have same errors.\n",
    "2. Confidence level= 0.95 (It is not mentioned in the question. So, I assumed confidence level is 0.95)\n",
    "3. Calculate paired differences for 10 folds.\n",
    "4. Calculate t-value and perform 2 tailed test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T value: -2.522293485296181\n",
      "T critical: -0.06447679010158362\n",
      "They have different errors\n"
     ]
    }
   ],
   "source": [
    "paired_difference=nb_validation_errors-knn_validation_errors\n",
    "mean=np.mean(paired_difference)\n",
    "std_dev=np.std(paired_difference)\n",
    "t_k_1=np.sqrt(FOLDS)*mean/std_dev\n",
    "t_critical=stats.t.ppf(0.95/2,df)\n",
    "print(\"T value:\",t_k_1)\n",
    "print(\"T critical:\",t_critical)\n",
    "if t_k_1>=t_critical and t_k_1<=-t_critical:\n",
    "    print(\"They have same error\")\n",
    "else:\n",
    "    print(\"They have different errors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.do the three classifiers have different errors?\n",
    "1. We need to perform **ANOVA** to check if all classifiers have different errors.\n",
    "2. Confidence level= 0.95 (It is not mentioned in the question. So, I assumed confidence level is 0.95)\n",
    "3. Calculate first estimator with between groups sum of squares.\n",
    "4. Calculate second estimator with within group sum of squares.\n",
    "5. Take ratio of both estimators and check if this value is greater than F-value at given confidence level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-value: 3.3541308285291986\n",
      "Estimator ratio: 4.588719236495855\n",
      "All classifiers have different errors\n"
     ]
    }
   ],
   "source": [
    "error_table=np.array(np.transpose([knn_validation_errors,nb_validation_errors,log_reg_validation_errors]))\n",
    "no_of_models=np.shape(error_table)[1]\n",
    "classifier_error_average=np.mean(error_table,axis=0)\n",
    "estimator_b=FOLDS*np.var(classifier_error_average)\n",
    "estimator_w=np.sum(np.var(error_table,axis=0)/no_of_models)\n",
    "f_value=stats.f.ppf(0.95,dfn=no_of_models-1,dfd=no_of_models*(FOLDS-1))\n",
    "print(\"F-value:\",f_value)\n",
    "print(\"Estimators ratio:\",estimator_b/estimator_w)\n",
    "if estimator_b/estimator_w<f_value:\n",
    "    print(\"All classifiers have same errors\")\n",
    "else:\n",
    "    print(\"All classifiers have different errors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.Use Bayes rule to decide on the label using the Glucose feature. Compute the mean and std of Glucose feature on the whole dataset (marginal distribution) and for each class separately, (class condition distribution Prob(x|C=0), Prob(x|C=1))). Assume that the feature is distributed according to the mean and std you computed. Compute the predictions for the 10 validation sets. Compare with the naivebayes classifier  (library) using only the Glucose feature\n",
    "\n",
    "1. Create NaiveBayes class with fit and predict methods.\n",
    "2. In training, calculate mean and variance of every class.\n",
    "3. Assumption:- Distribution is Gaussian.\n",
    "4. For calculation of conditional probability use gaussian function.\n",
    "5. For prediction, calculate P(C)P(X|C).\n",
    "6. If P(0)P(X|0)>P(1)P(X|1) yhen predict class 0 else predict class 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def __init__(self):\n",
    "        self.mean=[]\n",
    "        self.variance=[]\n",
    "        self.prior=[]\n",
    "    def conditional_probability(self,x):\n",
    "        result=[]\n",
    "        for i in range(self.mean.shape[0]):\n",
    "            numerator=np.exp(-((x-self.mean[i])**2)/(2*self.variance[i]))\n",
    "            denominator=np.sqrt(2*np.pi*self.variance[i])\n",
    "            result.append((numerator/denominator).item())\n",
    "        return np.array(result)\n",
    "    def fit(self,x_train,y_train):\n",
    "        no_of_classes=np.unique(y_train).shape[0]\n",
    "        for i in range(no_of_classes):\n",
    "            raw_data=x_train[y_train==i]\n",
    "            self.prior.append(raw_data.shape[0]/x_train.shape[0])\n",
    "            self.mean.append(np.mean(raw_data))\n",
    "            self.variance.append(np.var(raw_data))\n",
    "        self.mean=np.array(self.mean)\n",
    "        self.variance=np.array(self.variance)\n",
    "        self.prior=np.array(self.prior)\n",
    "    def predict(self,x):\n",
    "        predictions=[]\n",
    "        for x_data in x:\n",
    "            probabilities=self.conditional_probability(x_data)*self.prior\n",
    "            predictions.append(np.argmax(probabilities))\n",
    "        return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Library model  Custom model\n",
      "0       0.274194      0.274194\n",
      "1       0.161290      0.161290\n",
      "2       0.274194      0.274194\n",
      "3       0.258065      0.258065\n",
      "4       0.213115      0.213115\n",
      "5       0.262295      0.262295\n",
      "6       0.295082      0.295082\n",
      "7       0.229508      0.229508\n",
      "8       0.327869      0.327869\n",
      "9       0.278689      0.278689\n"
     ]
    }
   ],
   "source": [
    "x=data.loc[:,[\"Glucose\"]].values\n",
    "y=data.iloc[:,-1].values\n",
    "\n",
    "sklearn_error=[]\n",
    "custom_nb_error=[]\n",
    "\n",
    "\n",
    "for train,validation in kfold.split(y_train):\n",
    "    custom_model=NaiveBayes()\n",
    "    sklearn_model=GaussianNB()\n",
    "    \n",
    "    custom_model.fit(x[train],y[train])\n",
    "    predictions=custom_model.predict(x[validation])\n",
    "    error=np.sum(predictions!=y[validation])/np.shape(y[validation])[0]\n",
    "    custom_nb_error.append(error)\n",
    "    \n",
    "    sklearn_model.fit(x[train],y[train])\n",
    "    predictions=sklearn_model.predict(x[validation])\n",
    "    error=np.sum(predictions!=y[validation])/np.shape(y[validation])[0]\n",
    "    sklearn_error.append(error)\n",
    "\n",
    "results=pd.DataFrame({\"Library model\":sklearn_error,\"Custom model\":custom_nb_error})\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
